{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "33.3 DL Keras +TF.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNF3tZEB3fqjq30yExQwr8U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexBB999/junk/blob/master/33_3_DL_Keras_%2BTF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keCN73_WjfeG",
        "colab_type": "code",
        "outputId": "93e26773-dfec-4978-c647-8ebfb2507118",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        }
      },
      "source": [
        "pip install tensorflow==2.0.0-rc1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0-rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/7359227ccfb6e2ae2a8fe345db1d513f010282022a7a6a899530cc63c41f/tensorflow-2.0.0rc1-cp36-cp36m-manylinux2010_x86_64.whl (86.3MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3MB 57kB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc1) (0.3.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc1) (0.34.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc1) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc1) (0.2.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc1) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc1) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc1) (0.9.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc1) (3.2.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc1) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc1) (1.1.0)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019080602,>=1.14.0.dev2019080601\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/28/f2a27a62943d5f041e4a6fd404b2d21cb7c59b2242a4e73b03d9ba166552/tf_estimator_nightly-1.14.0.dev2019080601-py2.py3-none-any.whl (501kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 49.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc1) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc1) (1.18.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc1) (1.28.1)\n",
            "Collecting tb-nightly<1.15.0a20190807,>=1.15.0a20190806\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/88/24b5fb7280e74c7cf65bde47c171547fd02afb3840cff41bcbe9270650f5/tb_nightly-1.15.0a20190806-py3-none-any.whl (4.3MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3MB 45.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc1) (1.0.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0-rc1) (46.1.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow==2.0.0-rc1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow==2.0.0-rc1) (3.2.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0-rc1) (2.10.0)\n",
            "Installing collected packages: tf-estimator-nightly, tb-nightly, tensorflow\n",
            "  Found existing installation: tensorflow 2.2.0rc3\n",
            "    Uninstalling tensorflow-2.2.0rc3:\n",
            "      Successfully uninstalled tensorflow-2.2.0rc3\n",
            "Successfully installed tb-nightly-1.15.0a20190806 tensorflow-2.0.0rc1 tf-estimator-nightly-1.14.0.dev2019080601\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WE7HDjnMj64R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9sItGRwkBDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from tensorflow.keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2l9k4PstkLM4",
        "colab_type": "text"
      },
      "source": [
        "**Load the data and do our preprocessing:**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIv9aOeZkUVO",
        "colab_type": "code",
        "outputId": "79c80180-031c-4b19-d94d-c44eb6867569",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "input_dim = 784  # 28*28\n",
        "output_dim = nb_classes = 10\n",
        "batch_size = 128\n",
        "nb_epoch = 20\n",
        "\n",
        "X_train = X_train.reshape(60000, input_dim)\n",
        "X_test = X_test.reshape(10000, input_dim)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkG6I4FNkhy4",
        "colab_type": "text"
      },
      "source": [
        "**Next we one hot code our target variable using to_categorical function of Keras' utils module**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KR8WOzB5kmTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "Y_train = to_categorical(y_train, nb_classes)\n",
        "Y_test = to_categorical(y_test, nb_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVku_43vkqvh",
        "colab_type": "text"
      },
      "source": [
        "**Now, let's check the size of the data**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6HxTGI6kti8",
        "colab_type": "code",
        "outputId": "6516873b-b9bd-4809-85db-059c5d2f45a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m1FAaxblC-n",
        "colab_type": "code",
        "outputId": "028b3ce7-573b-4605-8dc1-067e32305ccd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CD_36_uQk6i7",
        "colab_type": "text"
      },
      "source": [
        "As you see, the size of each image is 784. In fact, all images in MNIST are 28 by 28 pixels and 784 is just the result of the multiplication of 28 by 28.\n",
        "\n",
        "**So, the data we have is a flattened version of the images where each row in the 28x28 matrix is concatenated side by side**.\n",
        "\n",
        "Let's plot some images and see what they look like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgdTU8yDk8vB",
        "colab_type": "code",
        "outputId": "0f73d411-b8b1-4fe7-d2a7-f91e0dbdfc12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20,5))\n",
        "\n",
        "plt.subplot(141)\n",
        "plt.imshow(X_train[123].reshape(28,28), cmap=\"gray\")\n",
        "plt.title(\"Label of the image: {}\".format(y_train[123]))\n",
        "\n",
        "plt.subplot(142)\n",
        "plt.imshow(X_train[124].reshape(28,28), cmap=\"gray\")\n",
        "plt.title(\"Label of the image: {}\".format(y_train[124]))\n",
        "\n",
        "plt.subplot(143)\n",
        "plt.imshow(X_train[125].reshape(28,28), cmap=\"gray\")\n",
        "plt.title(\"Label of the image: {}\".format(y_train[125]))\n",
        "\n",
        "plt.subplot(144)\n",
        "plt.imshow(X_train[126].reshape(28,28), cmap=\"gray\")\n",
        "plt.title(\"Label of the image: {}\".format(y_train[126]))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x360 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLOgopienAJf",
        "colab_type": "text"
      },
      "source": [
        "We're now ready to jump into building our ANN model.\n",
        "\n",
        "##**Defining the model**\n",
        "\n",
        "As we said before, we'll build our model using Sequential class of Keras' models module. Once we create our model as:\n",
        "\n",
        "**model = Sequential()**\n",
        "\n",
        "We'll start to add layers to our model object one by one (**that is, sequentially**). \n",
        "\n",
        "**The layer type we'll use is called the dense layer** which we'll import from the layers module of the Keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUjGgHJQnLDc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "# our first dense layer\n",
        "model.add(Dense(1028, input_shape=(784,), activation=\"relu\"))\n",
        "# our second dense layer\n",
        "model.add(Dense(1028, activation=\"relu\"))\n",
        "# last layer is the output layer.\n",
        "model.add(Dense(10, activation=\"softmax\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsY9DV_HnbE6",
        "colab_type": "text"
      },
      "source": [
        "**Note that, we set the neuron size of the output layer to 10**. \n",
        "\n",
        "**This is because in MNIST there are 10 classes**. \n",
        "\n",
        "**We also set the activation function of the output layer to softmax**\n",
        "\n",
        " We'll discuss why we use softmax as the activation function in the output layer.\n",
        " \n",
        "For now, we say that when we give an image as input to the model, our model will produce 10 probabilities for each of the 10 classes in the MNIST data.\n",
        " \n",
        "**The largest probability class will be the prediction of the model**.\n",
        "\n",
        "We can have a look at the structure of our ANN model using the summary() method of our model object:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brFC20CLn7I6",
        "colab_type": "code",
        "outputId": "c1de2e39-798e-4d6c-96b6-0f5ca3132cfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 1028)              806980    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1028)              1057812   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                10290     \n",
            "=================================================================\n",
            "Total params: 1,875,082\n",
            "Trainable params: 1,875,082\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_l35bKgoEmO",
        "colab_type": "text"
      },
      "source": [
        "**As you see, we have three dense layers of which the last one is the output layer**.\n",
        "\n",
        " In total, we have 1,875,082 parameters to be estimated in our mode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QDEv_RmoLsK",
        "colab_type": "text"
      },
      "source": [
        "**Compiling the model**\n",
        "\n",
        "Now we can compile our model.\n",
        "\n",
        "**When compiling the model, we define three things**:\n",
        "\n",
        "**The optimizer** that will be used in the training. If you don't know about the optimizers in deep learning, do not worry. We just use it in this checkpoint. But, we'll talk about them in the following checkpoints.\n",
        "\n",
        "**The loss function**. It's necessary to specify a loss function for a model. Training algorithms use this loss function and try to minimize it during the training. This is also something we'll cover in the next checkpoint.\n",
        "\n",
        "**The metri**c to measure the training performance of our model. In this example, we use the accuracy metric, since our task is a classification task and our dataset is a balanced one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrijdQExoenQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkELrdGPoiao",
        "colab_type": "text"
      },
      "source": [
        "##**Training the model**\n",
        "\n",
        "We're now ready to train our model.\n",
        "\n",
        " Training a model in Keras is done by calling the **fit() method** of the model object.\n",
        " \n",
        "  In the following, we train our model:\n",
        "\n",
        "**Using 128 as the batch size**. This is something we'll discuss in a later checkpoint.\n",
        "\n",
        "\n",
        "**Using 20 as the number of epochs**.\n",
        "\n",
        " In deep learning jargon, epoch means full use of all of the examples in the training data during the training the model. So, we'll train our model during 20 epochs, that's we'll use all of the observations in our training data 20 times when training our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYXwEItjo0o-",
        "colab_type": "code",
        "outputId": "afbfe647-4d53-4972-96f6-c8e090fd1b59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        }
      },
      "source": [
        "# setting verbose=1 prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fc63eb7e8c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fc63eb7e8c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "60000/60000 [==============================] - 17s 287us/sample - loss: 1.0399 - accuracy: 0.7833\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 16s 275us/sample - loss: 0.4300 - accuracy: 0.8888\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 17s 279us/sample - loss: 0.3457 - accuracy: 0.9055\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 16s 275us/sample - loss: 0.3073 - accuracy: 0.9145\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 16s 272us/sample - loss: 0.2822 - accuracy: 0.9206\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 16s 273us/sample - loss: 0.2630 - accuracy: 0.9263\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 16s 274us/sample - loss: 0.2473 - accuracy: 0.9305\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 17s 277us/sample - loss: 0.2339 - accuracy: 0.9348\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 16s 274us/sample - loss: 0.2220 - accuracy: 0.9382\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 16s 274us/sample - loss: 0.2116 - accuracy: 0.9409\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 16s 273us/sample - loss: 0.2021 - accuracy: 0.9437\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 16s 273us/sample - loss: 0.1934 - accuracy: 0.9461\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 16s 273us/sample - loss: 0.1852 - accuracy: 0.9480\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 16s 273us/sample - loss: 0.1779 - accuracy: 0.9502\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 16s 273us/sample - loss: 0.1709 - accuracy: 0.9524\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 16s 274us/sample - loss: 0.1642 - accuracy: 0.9539\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 16s 275us/sample - loss: 0.1584 - accuracy: 0.9560\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 16s 274us/sample - loss: 0.1528 - accuracy: 0.9578\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 16s 275us/sample - loss: 0.1474 - accuracy: 0.9589\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 17s 276us/sample - loss: 0.1423 - accuracy: 0.9604\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc643c9fc88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGe0eIk3qWXl",
        "colab_type": "text"
      },
      "source": [
        "##**Evaluating the model**\n",
        "\n",
        "The last step is to evaluate our model using the test set we set apart before.\n",
        " For this purpose, we use the **evaluate() method** of the model object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osvXyvlxqgou",
        "colab_type": "code",
        "outputId": "fd7d5c2b-c40d-4193-ac6f-26e0a4394b43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.1453822269245982\n",
            "Test accuracy: 0.9566\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qNtGcKvql3w",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "The test set accuracy of our model is almost 97%.  --**NO**\n",
        "\n",
        "Good job. Now it's your turn!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmkH8rK-q96_",
        "colab_type": "text"
      },
      "source": [
        "##**Assignments**\n",
        "\n",
        "To complete this assignment, create a Jupyter notebook containing your solutions to the following tasks:\n",
        "\n",
        "1 - In this task, you'll build an ANN and train and test it using the MNIST data.\n",
        "\n",
        " **This ANN should consist of two hidden and one output layer**.\n",
        " \n",
        "  **All hidden layers should be dense**.\n",
        " \n",
        "**The neuron sizes of the first layer and the second layer should be 32 and 16 respectivel**y.\n",
        "  \n",
        "   Train this model 20 epochs and compare your train and test set performance with the example in the checkpoint. \n",
        "   \n",
        "   Is there any difference? If so, why?\n",
        "\n",
        "2 - **You'll also build an ANN in this task**.\n",
        "\n",
        "**This time, this ANN should have 5 hidden layers and 1 output layer**.\n",
        "\n",
        "All the layers should be dense. \n",
        "\n",
        "**The neuron numbers for the hidden layers should be 1024, 512, 256, 128 and 64.**\n",
        "\n",
        "Train this model 20 epochs and test it using the same data from the previous task and compare your results. \n",
        "\n",
        "Is there any difference? If so, why?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03GJ6vSjsBS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "# our first dense layer,\n",
        "model.add(Dense(1028, input_shape=(784,), activation=\"relu\"))\n",
        "# our second dense layer\n",
        "model.add(Dense(1028,input_shape=(32,), activation=\"relu\"))\n",
        "#another layer\n",
        "model.add(Dense(1028,input_shape=(16,), activation=\"relu\"))\n",
        "# last layer is the output layer.\n",
        "model.add(Dense(10, activation=\"softmax\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly1tK6eKtLew",
        "colab_type": "code",
        "outputId": "8c8836a5-f27b-47eb-943c-cc180bb5b402",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 1028)              806980    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1028)              1057812   \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1028)              1057812   \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                10290     \n",
            "=================================================================\n",
            "Total params: 2,932,894\n",
            "Trainable params: 2,932,894\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKL1obyhtaeW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr6LQo9jtUNU",
        "colab_type": "code",
        "outputId": "727906ba-b904-41c4-b75b-8e5ce5371a2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        }
      },
      "source": [
        "# setting verbose=1 prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fc63b3a28c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fc63b3a28c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "60000/60000 [==============================] - 28s 472us/sample - loss: 1.0855 - accuracy: 0.7811\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 28s 460us/sample - loss: 0.3914 - accuracy: 0.8937\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 28s 460us/sample - loss: 0.3153 - accuracy: 0.9107\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 28s 459us/sample - loss: 0.2784 - accuracy: 0.9203\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 27s 454us/sample - loss: 0.2526 - accuracy: 0.9277\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 27s 449us/sample - loss: 0.2320 - accuracy: 0.9330\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 27s 451us/sample - loss: 0.2151 - accuracy: 0.9381\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 30s 502us/sample - loss: 0.2002 - accuracy: 0.9428\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 26s 436us/sample - loss: 0.1876 - accuracy: 0.9467\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 26s 441us/sample - loss: 0.1759 - accuracy: 0.9496\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 26s 436us/sample - loss: 0.1650 - accuracy: 0.9533\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 26s 436us/sample - loss: 0.1560 - accuracy: 0.9558\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 26s 440us/sample - loss: 0.1474 - accuracy: 0.9583\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 26s 439us/sample - loss: 0.1398 - accuracy: 0.9609\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 26s 440us/sample - loss: 0.1329 - accuracy: 0.9624\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 26s 438us/sample - loss: 0.1262 - accuracy: 0.9648\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 26s 437us/sample - loss: 0.1201 - accuracy: 0.9665\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 26s 438us/sample - loss: 0.1145 - accuracy: 0.9683\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 26s 438us/sample - loss: 0.1094 - accuracy: 0.9696\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 27s 444us/sample - loss: 0.1045 - accuracy: 0.9706\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc63b2af048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8Pyqmz1wP6V",
        "colab_type": "code",
        "outputId": "7fd08c09-6deb-4677-e8fc-119ac343cf66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.11610818285010754\n",
            "Test accuracy: 0.9659\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNeCMnejwt4N",
        "colab_type": "text"
      },
      "source": [
        "**PART 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oe8L5cznwxxn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model = Sequential()\n",
        "# our first dense layer,\n",
        "model.add(Dense(1028, input_shape=(784,), activation=\"relu\"))\n",
        "#HIDDEN LAYER\n",
        "model.add(Dense(1028,input_shape=(512,), activation=\"relu\"))\n",
        "#HIDDEN LAYER\n",
        "model.add(Dense(1028,input_shape=(256,), activation=\"relu\"))\n",
        "#HIDDEN LAYER\n",
        "model.add(Dense(1028,input_shape=(128,), activation=\"relu\"))\n",
        "#HIDDEN LAYER\n",
        "model.add(Dense(1028,input_shape=(64,), activation=\"relu\"))\n",
        "# last layer is the output layer.\n",
        "model.add(Dense(10, activation=\"softmax\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2VUYEa4xo-Z",
        "colab_type": "code",
        "outputId": "1f199237-684f-4d86-93b2-e949a5d95631",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_10 (Dense)             (None, 1028)              806980    \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1028)              1057812   \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1028)              1057812   \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1028)              1057812   \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1028)              1057812   \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 10)                10290     \n",
            "=================================================================\n",
            "Total params: 5,048,518\n",
            "Trainable params: 5,048,518\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S406Un8lxzQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ7LD7Kdx5vq",
        "colab_type": "code",
        "outputId": "ea30f91c-90c5-4d8e-fb23-dd33afa7e4c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        }
      },
      "source": [
        "# setting verbose=1 prints out some results after each epoch\n",
        "model.fit(X_train, Y_train, batch_size=batch_size, epochs=20, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fc6441bf620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7fc6441bf620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "60000/60000 [==============================] - 45s 755us/sample - loss: 1.3328 - accuracy: 0.7025\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 45s 758us/sample - loss: 0.3815 - accuracy: 0.8925\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 46s 759us/sample - loss: 0.2902 - accuracy: 0.9166\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 46s 762us/sample - loss: 0.2456 - accuracy: 0.9288\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 46s 759us/sample - loss: 0.2152 - accuracy: 0.9382\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 45s 758us/sample - loss: 0.1911 - accuracy: 0.9448\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 45s 758us/sample - loss: 0.1722 - accuracy: 0.9506\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 45s 758us/sample - loss: 0.1551 - accuracy: 0.9561\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 48s 796us/sample - loss: 0.1415 - accuracy: 0.9591\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 46s 766us/sample - loss: 0.1291 - accuracy: 0.9629\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 46s 763us/sample - loss: 0.1191 - accuracy: 0.9653\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 46s 760us/sample - loss: 0.1100 - accuracy: 0.9683\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 46s 761us/sample - loss: 0.1014 - accuracy: 0.9710\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 46s 762us/sample - loss: 0.0937 - accuracy: 0.9729\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 46s 760us/sample - loss: 0.0873 - accuracy: 0.9746\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 46s 762us/sample - loss: 0.0814 - accuracy: 0.9768\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 46s 763us/sample - loss: 0.0756 - accuracy: 0.9788\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 46s 760us/sample - loss: 0.0701 - accuracy: 0.9801\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 46s 760us/sample - loss: 0.0667 - accuracy: 0.9810\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 46s 767us/sample - loss: 0.0617 - accuracy: 0.9824\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc639d5cb38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gndQpDp02ECQ",
        "colab_type": "code",
        "outputId": "5422fc22-644e-41f8-de6e-343a11225d73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.08714763048002497\n",
            "Test accuracy: 0.9722\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}